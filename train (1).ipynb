{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Code1**"
      ],
      "metadata": {
        "id": "Sau8TTKmb3fJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FEK5pDOMJuI",
        "outputId": "8efc70bb-e88e-45eb-fded-8251e12ea086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.9.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
        "\n",
        "# Define your SMILESDataset class\n",
        "class SMILESDataset(Dataset):\n",
        "    def __init__(self, data_file):\n",
        "        self.data = pd.read_csv(data_file, header=None, names=['smiles'])\n",
        "        self.data['mol'] = self.data['smiles'].apply(Chem.MolFromSmiles)\n",
        "        self.data[['logp', 'rotb', 'molwt', 'qed', 'hba', 'hbd']] = self.data['mol'].apply(compute_descriptors)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        smiles = self.data.iloc[idx]['smiles']\n",
        "        features = self.data.iloc[idx][['logp', 'rotb', 'molwt', 'qed', 'hba', 'hbd']].values.astype(np.float32)\n",
        "        return smiles, features\n",
        "\n",
        "# Compute molecular descriptors\n",
        "def compute_descriptors(mol):\n",
        "    if mol is None:\n",
        "        # Return default values if molecule is None\n",
        "        return pd.Series([0, 0, 0, 0, 0, 0])\n",
        "    else:\n",
        "        molwt = Descriptors.MolWt(mol)\n",
        "        logp = Descriptors.MolLogP(mol)\n",
        "        hbd = rdMolDescriptors.CalcNumHBD(mol)\n",
        "        hba = rdMolDescriptors.CalcNumHBA(mol)\n",
        "        rotb = Descriptors.NumRotatableBonds(mol)\n",
        "        return pd.Series([logp, rotb, molwt, Descriptors.qed(mol), hba, hbd])\n",
        "\n",
        "\n",
        "\n",
        "dataset = SMILESDataset('train.smi')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KDErf4usiEp",
        "outputId": "31215d85-8446-4f7d-9b96-a9db9a4200ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[12:09:03] SMILES Parse Error: extra open parentheses for input: 'Cn1c(N(Cc2ccc(C(=O)N=c3nn[nH][nH]3)cc2)C2CCC(C(C)(C)C)CC2)nc2cc(O'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoPcHq7BPKYy",
        "outputId": "b0c80480-f67b-4dde-cfc3-15b30b1fc703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63533"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the char_to_index dictionary\n",
        "char_to_index = {\n",
        "    'C': 0,\n",
        "    'O': 1,\n",
        "    'N': 2,\n",
        "    'H': 3,\n",
        "    '(': 4,\n",
        "    ')': 5,\n",
        "    '=': 6,\n",
        "    '#': 7,\n",
        "    '1': 8,\n",
        "    '2': 9,\n",
        "    '3': 10,\n",
        "    '4': 11,\n",
        "    '5': 12,\n",
        "    '6': 13,\n",
        "    '7': 14,\n",
        "    '8': 15,\n",
        "    '9': 16,\n",
        "    '0': 17,\n",
        "}\n",
        "\n",
        "# Create index_to_char dictionary by reversing char_to_index\n",
        "index_to_char = {v: k for k, v in char_to_index.items()}"
      ],
      "metadata": {
        "id": "unXjRq8HNExy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def preprocess_smiles(smiles, max_length=100):\n",
        "    # Initialize an array for the padded numerical representation\n",
        "    padded_representation = np.full(max_length, -1)  # Use '_' for padding\n",
        "\n",
        "    # Tokenize SMILES string and convert to numerical representation\n",
        "    numerical_representation = [char_to_index.get(c, -1) for c in smiles]\n",
        "\n",
        "    # Truncate or pad numerical representation to the fixed length\n",
        "    num_tokens = min(len(numerical_representation), max_length)\n",
        "    padded_representation[:num_tokens] = numerical_representation[:num_tokens]\n",
        "\n",
        "    return padded_representation\n",
        "\n",
        "\n",
        "def preprocess_features(features):\n",
        "    # Normalize features if necessary\n",
        "    # Convert features to tensors\n",
        "    features_list = [f for f in features]\n",
        "\n",
        "    # Normalize features\n",
        "    features_array = np.array(features_list)\n",
        "    normalized_features = (features_array - np.mean(features_array)) / np.std(features_array)\n",
        "\n",
        "    # Convert features to tensors\n",
        "    features_tensor = torch.tensor(normalized_features, dtype=torch.float32)\n",
        "\n",
        "    return features_tensor\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.rnn = nn.LSTM(self.input_size, self.hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reshape input tensor to have the sequence length dimension\n",
        "        x = x.unsqueeze(1)\n",
        "        batch_size = x.size(0)\n",
        "        init_hidden = (torch.zeros(1, batch_size, self.hidden_size),\n",
        "                       torch.zeros(1, batch_size, self.hidden_size))\n",
        "        out, _ = self.rnn(x, init_hidden)\n",
        "        out = self.fc(out[:, -1, :])  # Select the last output in the sequence\n",
        "        #print(out.shape)\n",
        "        return out\n",
        "\n",
        "\n",
        "# Define Discriminator architecture\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        x_tensor = torch.tensor(x, dtype=torch.float32)\n",
        "        #print(x_tensor.shape)\n",
        "        out = torch.relu(self.fc1(x_tensor))\n",
        "        #print(1)\n",
        "        out = torch.sigmoid(self.fc2(out))\n",
        "        return out\n",
        "\n",
        "# Training loop\n",
        "def train(generator, discriminator, train_loader, criterion, g_optimizer, d_optimizer, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        for smiles, features in train_loader:\n",
        "            # Preprocess SMILES and features\n",
        "            processed_features = preprocess_features(features)\n",
        "            processed_smiles = preprocess_smiles(smiles)\n",
        "\n",
        "            # Train Discriminator\n",
        "            d_optimizer.zero_grad()\n",
        "            real_output = discriminator(processed_smiles)\n",
        "            #print(0)\n",
        "            fake_output = discriminator(generator(processed_features))\n",
        "            d_loss = criterion(real_output, torch.ones_like(real_output)) + criterion(fake_output, torch.zeros_like(fake_output))\n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "            # Train Generator\n",
        "            g_optimizer.zero_grad()\n",
        "            fake_output = discriminator(generator(processed_features))\n",
        "            g_loss = criterion(fake_output, torch.ones_like(fake_output))\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], G_Loss: {g_loss.item()}, D_Loss: {d_loss.item()}')\n",
        "\n",
        "# Set hyperparameters\n",
        "input_size = 6  # Number of molecular descriptors\n",
        "hidden_size = 128\n",
        "output_size = 100  # Size of vocabulary for SMILES tokens\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load your dataset\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Initialize Generator and Discriminator\n",
        "generator = Generator(input_size=6, hidden_size=128, output_size=100)\n",
        "discriminator = Discriminator(input_size=100, hidden_size=128, output_size=1)  # Assuming features have the same size\n",
        "\n",
        "# Define loss function and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=learning_rate)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the models\n",
        "train(generator, discriminator, train_loader, criterion, g_optimizer, d_optimizer, num_epochs)\n"
      ],
      "metadata": {
        "id": "uRYoZg9LdGq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to convert numerical tokens to SMILES\n",
        "def convert_to_smiles(output_tensor, char_to_index):\n",
        "    # Convert tensor to numpy array\n",
        "    output_array = output_tensor.squeeze().detach().numpy()\n",
        "    # Map numerical tokens to characters in SMILES vocabulary\n",
        "    smiles_chars = [char for token in output_array for char, index in char_to_index.items() if index == int(token)]\n",
        "    # Join characters to form SMILES string\n",
        "    smiles_string = ''.join(smiles_chars)\n",
        "    return smiles_string\n",
        "\n",
        "# Test the generator\n",
        "def test_generator(generator, feature_vector, char_to_index):\n",
        "    # Convert feature vector to tensor\n",
        "    feature_tensor = torch.tensor(feature_vector, dtype=torch.float32)\n",
        "    # Generate SMILES tokens\n",
        "    generated_tokens = generator(feature_tensor.unsqueeze(0))*100\n",
        "    print(generated_tokens)\n",
        "    # Convert tokens to SMILES string\n",
        "    generated_smiles = convert_to_smiles(generated_tokens, char_to_index)\n",
        "    return generated_smiles\n",
        "\n",
        "# Example feature vector\n",
        "example_feature = [5.5633998e+00, 6.0000000e+00, 6.0275702e+02, 3.0880994e-01,\n",
        "        8.0000000e+00, 1.0000000e+00]\n",
        "example_feature = preprocess_features(example_feature)\n",
        "\n",
        "\n",
        "# Test the generator\n",
        "generated_smiles = test_generator(generator, example_feature, char_to_index)\n",
        "print(\"Generated SMILES:\", generated_smiles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74f_vPVn4VYx",
        "outputId": "47443e48-3fe2-4a4a-94ee-8776c04c7454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ -1.9386,   7.7949,   4.6882,   1.2334,  -7.6688,  -1.7499,  -7.9764,\n",
            "          -0.4336,  -2.1415,   1.3494,   0.4190,   9.9071,  -6.3024,  -1.0888,\n",
            "          -4.9484,  -2.6139,   0.5625,   5.8099,  -6.9510,  -6.1652,   0.7955,\n",
            "           9.6862,   8.4107,  -0.6118,  -7.7706,   8.0619,   8.5937,  -8.2207,\n",
            "          -5.7854,  10.1466,   8.5191,   2.0062,  10.8956,  -2.4045,   5.3824,\n",
            "          -9.9102,   4.3019,   0.0130,  -5.5973,   8.7250,   4.9875,  -1.5318,\n",
            "          -7.9905, -11.6901,  -1.7776,   1.3973,   8.2043,  -9.0098,   9.8728,\n",
            "          -3.4986,   5.9645,  -1.9910,  -7.2768,   6.4773,  -2.8570,   0.6650,\n",
            "          -5.4184,  -1.7903,  -7.9534,  -0.1328,  -6.2866,  -7.6002,  -0.2442,\n",
            "           4.0442,   5.5332,  -1.7552,  -3.1745,  -2.6822,  -2.1126,   9.8187,\n",
            "          -6.7511,  -2.6546,  -1.7342,  -4.7961,   1.0328,   0.4165,  -4.3086,\n",
            "           7.3225,   6.2127,  10.1198,  -0.7599,  -2.1322,   2.4347,  -6.6218,\n",
            "          -4.4297,  -6.2012,   8.3669,  -0.7065,  -2.1720,  -2.1602,   8.0550,\n",
            "           0.4412,  -7.4690,   1.3875,  -2.2303,   5.8051,   4.1187,   5.9528,\n",
            "           3.3143,   8.1594]], grad_fn=<MulBackward0>)\n",
            "Generated SMILES: #(OCOC2C)C21C1131N3)(C1(O12)=CCC()2OC#=3CN1C1CO)()H1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-399237da5fac>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  feature_tensor = torch.tensor(feature_vector, dtype=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNSX36F7ABHZ",
        "outputId": "9eb3e707-c66c-45d9-ba06-fa2e5018c60f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('COc1ccc(CN2CC(C)C(OC)CN(C)C(=O)c3cc(NC(=O)c4nc5ccccc5s4)ccc3OCC2C)cc1',\n",
              " array([5.5633998e+00, 6.0000000e+00, 6.0275702e+02, 3.0880994e-01,\n",
              "        8.0000000e+00, 1.0000000e+00], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xy = preprocess_smiles(\"NCOCNCC=OCCO=OCCNCOCOOCNCN(COCNO(CNNOCCC)N)COONCCOCN(CC()CCOCOCCNCON#C\")"
      ],
      "metadata": {
        "id": "SdUQgpFMAITI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaVUMyW8CI2_",
        "outputId": "19826626-0dce-4bda-9869-78b8840ccaba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 0., 1., 0., 2., 0., 0., 5., 1., 0., 0., 1., 5., 1., 0., 0., 2.,\n",
              "       0., 1., 0., 1., 1., 0., 2., 0., 2., 3., 0., 1., 0., 2., 1., 3., 0.,\n",
              "       2., 2., 1., 0., 0., 0., 4., 2., 4., 0., 1., 1., 2., 0., 0., 1., 0.,\n",
              "       2., 3., 0., 0., 3., 4., 0., 0., 1., 0., 1., 0., 0., 2., 0., 1., 2.,\n",
              "       6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(xy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCNHGRohCq2-",
        "outputId": "bc8a4da8-f049-40b0-f94d-2b9705871d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "\n",
        "def visualize_molecule(smiles):\n",
        "    # Convert SMILES string to RDKit molecule object\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    # Check if the conversion was successful\n",
        "    if mol is not None:\n",
        "        # Generate a 2D depiction of the molecule\n",
        "        img = Draw.MolToImage(mol)\n",
        "        # Display the image\n",
        "        img.show()\n",
        "    else:\n",
        "        print(\"Invalid SMILES string:\", smiles)\n",
        "\n",
        "# Example SMILES string\n",
        "smiles = \"(OCOC2C)C21C1131N3)(C1(O12)=CCC2OC=3CN1C1CO)H\"\n",
        "# Visualize the molecule\n",
        "visualize_molecule(smiles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opdXUn01Cy_W",
        "outputId": "ca239759-66bb-4a14-c8b3-5fe7c4d43449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid SMILES string: (OCOC2C)C21C1131N3)(C1(O12)=CCC2OC=3CN1C1CO)H\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[12:32:44] SMILES Parse Error: syntax error while parsing: (OCOC2C)C21C1131N3)(C1(O12)=CCC2OC=3CN1C1CO)H\n",
            "[12:32:44] SMILES Parse Error: Failed parsing SMILES '(OCOC2C)C21C1131N3)(C1(O12)=CCC2OC=3CN1C1CO)H' for input: '(OCOC2C)C21C1131N3)(C1(O12)=CCC2OC=3CN1C1CO)H'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "\n",
        "def visualize_molecule(smiles, filename):\n",
        "    # Convert SMILES string to RDKit molecule object\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    # Check if the conversion was successful\n",
        "    if mol is not None:\n",
        "        # Generate a 2D depiction of the molecule\n",
        "        img = Draw.MolToImage(mol)\n",
        "        # Save the image to a file\n",
        "        img.save(filename)\n",
        "    else:\n",
        "        print(\"Invalid SMILES string:\", smiles)\n",
        "\n",
        "# Example SMILES string\n",
        "smiles = \"COc1ccc(CN2CC(C)C(OC)CN(C)C(=O)c3cc(NC(=O)c4nc5ccccc5s4)ccc3OCC2C)cc1\"\n",
        "# Specify the filename to save the image\n",
        "filename = \"molecule.png\"\n",
        "# Visualize the molecule and save the image\n",
        "visualize_molecule(smiles, filename)\n"
      ],
      "metadata": {
        "id": "H2iZpLIkRmwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "\n",
        "def correct_smiles(smiles):\n",
        "    # Correct mismatched parentheses\n",
        "    num_open_parentheses = smiles.count('(')\n",
        "    num_close_parentheses = smiles.count(')')\n",
        "    if num_open_parentheses > num_close_parentheses:\n",
        "        smiles += ')' * (num_open_parentheses - num_close_parentheses)\n",
        "    elif num_open_parentheses < num_close_parentheses:\n",
        "        smiles = '(' * (num_close_parentheses - num_open_parentheses) + smiles\n",
        "\n",
        "    # Replace invalid bonds and correct other syntax errors\n",
        "    invalid_bonds = ['=', '#', '/', '\\\\', ':', '.']\n",
        "    for bond in invalid_bonds:\n",
        "        smiles = smiles.replace(' ' + bond + ' ', bond)\n",
        "    smiles = smiles.replace('C1C', 'C1')\n",
        "    smiles = smiles.replace('1C', 'C1')\n",
        "\n",
        "    # Handle additional syntax corrections based on common issues\n",
        "\n",
        "    return smiles\n",
        "\n",
        "# Example usage\n",
        "incorrect_smiles = \"(OCOC2C)C21C1131N3)(C1(O12)=CCC2OC=3CN1C1CO)H\"\n",
        "corrected_smiles = correct_smiles(incorrect_smiles)\n",
        "print(\"Corrected SMILES:\", corrected_smiles)\n",
        "\n",
        "# Convert corrected SMILES to RDKit molecule object\n",
        "mol = Chem.MolFromSmiles(corrected_smiles)\n",
        "if mol is not None:\n",
        "    # Generate a 2D depiction of the molecule\n",
        "    Chem.Draw.MolToImage(mol).show()\n",
        "else:\n",
        "    print(\"Failed to parse corrected SMILES.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nWr0JWOR0D1",
        "outputId": "c11f9411-db5f-4e76-fdde-e4256fad3921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrected SMILES: ((OCOC2C)C2C11131N3)(C1(O12)=CCC2OC=3CNC11O)H\n",
            "Failed to parse corrected SMILES.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[12:38:15] SMILES Parse Error: syntax error while parsing: ((OCOC2C)C2C11131N3)(C1(O12)=CCC2OC=3CNC11O)H\n",
            "[12:38:15] SMILES Parse Error: Failed parsing SMILES '((OCOC2C)C2C11131N3)(C1(O12)=CCC2OC=3CNC11O)H' for input: '((OCOC2C)C2C11131N3)(C1(O12)=CCC2OC=3CNC11O)H'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bzsjHocmTgRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **code2**"
      ],
      "metadata": {
        "id": "bMbHJfZhb8Zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'train.smi' contains your dataset\n",
        "with open('train.smi', 'r') as f:\n",
        "    smiles_strings = f.readlines()\n",
        "\n",
        "# Collect unique characters from all SMILES strings\n",
        "smiles_vocab = set()\n",
        "for smiles in smiles_strings:\n",
        "    smiles_vocab.update(set(smiles.strip()))\n",
        "\n",
        "# Print the size of the SMILES vocabulary\n",
        "print(\"Size of SMILES vocabulary:\", len(smiles_vocab))\n"
      ],
      "metadata": {
        "id": "9UFi8MHXb-_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0447f6e-1e1d-4678-88dd-0a80736028fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of SMILES vocabulary: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "# Define your SMILESDataset class\n",
        "class SMILESDataset(Dataset):\n",
        "    def __init__(self, data_file):\n",
        "        self.data = pd.read_csv(data_file, header=None, names=['smiles'])\n",
        "        self.data['fingerprint'] = self.data['smiles'].apply(generate_morgan_fingerprint)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fingerprint = self.data.iloc[idx]['fingerprint']\n",
        "        if fingerprint is None:\n",
        "            # Handle invalid molecule\n",
        "            return None\n",
        "        return fingerprint\n",
        "\n",
        "# Generate Morgan fingerprints\n",
        "def generate_morgan_fingerprint(smiles, radius=2, num_bits=2048):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None\n",
        "    fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=num_bits)\n",
        "    return np.array(fingerprint, dtype=np.float32)\n",
        "\n",
        "dataset = SMILESDataset('train.smi')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "aQXFVKw8AKCN",
        "outputId": "e1f27a07-0372-410d-c132-0fa4b7285e77"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (64x2048 and 32x256)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3f17594844eb>\u001b[0m in \u001b[0;36m<cell line: 123>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# Train the models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-3f17594844eb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(generator, discriminator, train_loader, g_criterion, d_criterion, g_optimizer, d_optimizer, num_epochs, clip_value)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mreal_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfingerprints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mfake_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfingerprints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mreal_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfingerprints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mfake_fingerprints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfingerprints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mfake_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_fingerprints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-3f17594844eb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x2048 and 32x256)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Generator architecture\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.fc = nn.Linear(self.input_size, self.hidden_size)\n",
        "        self.rnn = nn.LSTM(self.hidden_size, self.hidden_size, num_layers=2, batch_first=True)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc(x))\n",
        "        x = x.unsqueeze(1)\n",
        "        batch_size = x.size(0)\n",
        "        init_hidden = (torch.zeros(2, batch_size, self.hidden_size),\n",
        "                       torch.zeros(2, batch_size, self.hidden_size))\n",
        "        out, _ = self.rnn(x, init_hidden)\n",
        "        out = self.out(out[:, -1, :])\n",
        "        out = nn.functional.softmax(out, dim=1)  # Apply softmax to convert logits to probabilities\n",
        "        return out\n",
        "\n",
        "# Define the Discriminator architecture\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n",
        "        self.fc2 = nn.Linear(self.hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(x.shape)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        print(x.shape)\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Training loop\n",
        "def train(generator, discriminator, train_loader, g_criterion, d_criterion, g_optimizer, d_optimizer, num_epochs, clip_value=1.0):\n",
        "    for epoch in range(num_epochs):\n",
        "        generator.train()\n",
        "        discriminator.train()\n",
        "        for fingerprints in train_loader:\n",
        "            if fingerprints is None:\n",
        "                continue\n",
        "\n",
        "            # Train Discriminator\n",
        "            d_optimizer.zero_grad()\n",
        "            real_labels = torch.ones(fingerprints.size(0), 1)\n",
        "            fake_labels = torch.zeros(fingerprints.size(0), 1)\n",
        "            real_outputs = discriminator(fingerprints)\n",
        "            fake_fingerprints = generator(fingerprints)\n",
        "            fake_outputs = discriminator(fake_fingerprints.detach())\n",
        "            d_loss_real = d_criterion(real_outputs, real_labels)\n",
        "            d_loss_fake = d_criterion(fake_outputs, fake_labels)\n",
        "            d_loss = d_loss_real + d_loss_fake\n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "            # Train Generator\n",
        "            g_optimizer.zero_grad()\n",
        "            fake_outputs = discriminator(fake_fingerprints)\n",
        "            g_loss = g_criterion(fake_outputs, real_labels)\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], G_Loss: {g_loss.item()}, D_Loss: {d_loss.item()}')\n",
        "\n",
        "# Set hyperparameters\n",
        "input_size = 2048  # Size of Morgan fingerprint\n",
        "hidden_size = 256\n",
        "output_size = 32  # Size of SMILES vocabulary\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Load your dataset\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Initialize Generator and Discriminator\n",
        "generator = Generator(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
        "discriminator = Discriminator(input_size=output_size, hidden_size=hidden_size)\n",
        "\n",
        "# Define loss functions and optimizers\n",
        "g_criterion = nn.BCELoss()\n",
        "d_criterion = nn.BCELoss()\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=learning_rate)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the models\n",
        "train(generator, discriminator, train_loader, g_criterion, d_criterion, g_optimizer, d_optimizer, num_epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "XJfaxCkrA23-",
        "outputId": "771fc288-c114-4eb2-cda3-63b6f9337a01"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 2048])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (64x2048 and 32x256)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0496597faa37>\u001b[0m in \u001b[0;36m<cell line: 92>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m# Train the models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-0496597faa37>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(generator, discriminator, train_loader, g_criterion, d_criterion, g_optimizer, d_optimizer, num_epochs, clip_value)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mreal_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfingerprints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mfake_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfingerprints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mreal_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfingerprints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mfake_fingerprints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfingerprints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mfake_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_fingerprints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-0496597faa37>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x2048 and 32x256)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2uXHrJ6CEKaH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}